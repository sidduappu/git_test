import boto3
import csv
import os
from datetime import datetime

config_client = boto3.client('config')
s3_client = boto3.client('s3')

CONFIG_RULE_NAME = os.environ['CONFIG_RULE_NAME']
S3_BUCKET = os.environ['S3_BUCKET']

def lambda_handler(event, context):
    response = config_client.get_compliance_details_by_config_rule(
        ConfigRuleName=CONFIG_RULE_NAME,
        ComplianceTypes=['NON_COMPLIANT']
    )
    
    evaluations = response.get('EvaluationResults', [])
    if not evaluations:
        print("All resources are compliant.")
        return {"status": "compliant"}

    file_name = f"non_compliant_resources_{datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')}.csv"
    local_file = f"/tmp/{file_name}"

    with open(local_file, 'w', newline='') as csvfile:
        fieldnames = ['ResourceType', 'ResourceId']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()

        for eval_result in evaluations:
            qualifier = eval_result['EvaluationResultIdentifier']['EvaluationResultQualifier']
            writer.writerow({
                'ResourceType': qualifier['ResourceType'],
                'ResourceId': qualifier['ResourceId']
            })

    s3_client.upload_file(local_file, S3_BUCKET, file_name)
    print(f"Uploaded {file_name} to s3://{S3_BUCKET}/{file_name}")

    return {"status": "non_compliant", "file": file_name}
